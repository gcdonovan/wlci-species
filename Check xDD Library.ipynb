{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep up with current literature on species of interest this notebook accesses eXtract Dark Data (xDD), formaly known as GeoDeepDive.  The xDD database is continuously being updated with published scientific literature from many of the large publishers including Elsiver, Taylor & Francis, GSA, and USGS.  We are currently working with the xDD team  on a number of tools and techniques for a) identifying literature potentially applicable to species-based research and b) using natural language processing tools to pull specific data from those sources for use. This is an ongoing effort that will result in improved production capabilities over time.\n",
    "\n",
    "In the near term, we take advantage of some basic and enhanced search functionality to identify potential articles of interested in the xDD library of millions of documents that are increasing daily. The xdd module in the bispy package contains some search and packaging functionality that interfaces with the xDD REST API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import needed packages\n",
    "import requests\n",
    "import json\n",
    "import bispy\n",
    "from IPython.display import display\n",
    "from joblib import Parallel, delayed\n",
    "import random\n",
    "\n",
    "xdd = bispy.xdd.Xdd()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open source WLCI list created from build-specie-list.ipynb\n",
    "with open(\"cache/WLCI Species List from Literature.json\", \"r\") as f:\n",
    "    sp_list = json.loads(f.read())\n",
    "sci_name_list = list(set([spp[\"Scientific Name\"] for spp in sp_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use joblib to run multiple requests to xDD in parallel via scientific names\n",
    "xdd_results = Parallel(n_jobs=8)(delayed(xdd.snippets)(name) for name in [r for r in sp_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdd_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_xdd = [i for i in xdd_results if i[\"processing_metadata\"][\"status\"] == \"success\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache the array of retrieved documents \n",
    "with open('cache/xdd.json', 'w') as f:\n",
    "    f.write(json.dumps(success_xdd, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cache/xdd.json\", \"r\") as f:\n",
    "    xdd_cache = json.loads(f.read())\n",
    "\n",
    "print(len(xdd_cache))\n",
    "display(xdd_cache[random.randint(0,len(xdd_cache)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
